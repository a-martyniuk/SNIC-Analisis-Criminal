# Gu铆a del Proyecto de An谩lisis SNIC

Este documento registra los pasos realizados para configurar el proyecto de An谩lisis Criminal SNIC e implementar el pipeline ETL inicial.

## 1. Inicializaci贸n del Proyecto
- Directorio de proyecto creado: `d:\Projects\SNIC-Analisis-Criminal`
- Entorno Python y repositorio Git inicializados.
- Estructura de directorios creada:
    - `src/`: C贸digo fuente para ETL
    - `data/`: Almacenamiento de datos (raw, processed, final)
    - `notebooks/`: Notebooks de an谩lisis

## 2. Implementaci贸n del Pipeline ETL
Implementamos un pipeline ETL (Extracci贸n, Transformaci贸n, Carga) robusto en `src/`.

### Extracci贸n (`src/extract.py`)
- **Funci贸n**: Descarga datos reales del SNIC desde `cloud-snic.minseg.gob.ar`.
- **Estado**: listo para producci贸n. Utiliza el enlace directo CSV para datos departamentales.

### Transformaci贸n (`src/transform.py`)
- **Funci贸n**: Limpia y normaliza los datos CSV crudos.
- **L贸gica Clave**: Maneja codificaci贸n `latin-1` y delimitador de punto y coma (`;`).
- **Pasos**:
    - Elimina filas con valores clave faltantes.
    - Convierte tipos (ej. `anio` a int).
    - Estandariza nombres de columnas.

### Carga (`src/load.py`)
- **Funci贸n**: Guarda los datos procesados en un formato altamente eficiente.
- **Salida**: `data/final/snic_analytics.parquet`.

### Orquestaci贸n del Pipeline (`src/pipeline.py`)
- Conecta todos los pasos.
- Comando de ejecuci贸n: `python src/pipeline.py`.

## 3. Configuraci贸n de An谩lisis de Datos
- **Dependencias**: Se agregaron `matplotlib`, `seaborn`, `jupyter` a `requirements.txt`.
- **Notebook**: Se cre贸 `notebooks/01_eda.ipynb` para An谩lisis Exploratorio de Datos.

## 4. C贸mo Ejecutar
1. **Instalar Dependencias**:
   ```bash
   pip install -r requirements.txt
   ```
2. **Ejecutar Pipeline ETL**:
   ```bash
   python src/pipeline.py
   ```
3. **Ejecutar An谩lisis**:
   ```bash
   jupyter notebook notebooks/01_eda.ipynb
   ```

## 5. Visualizaci贸n (Dashboard Interactivo)
Se implement贸 un dashboard con Streamlit para la exploraci贸n din谩mica de datos.

### Caracter铆sticas
- **Pestana 1: Resumen General**: KPIs con comparativa interanual (Var %) y gr谩ficos de top provincias.
- **Limpieza Visual**: Mayor espacio para gr谩ficos y men煤s.
- **Referencias Din谩micas**: En el men煤 lateral, debajo del selector de delitos, se agreg贸 un desplegable **"癸 驴Qu茅 significa cada delito?"** que explica en lenguaje llano los delitos seleccionados.
- **Pestana 2: Tendencias**: Gr谩ficos de l铆nea y 谩rea para ver la evoluci贸n hist贸rica.
- **Mapa Geogr谩fico**: La pesta帽a "Detalle Geogr谩fico" ahora muestra un mapa de Argentina con burbujas rojas sobre **OpenStreetMap**, permitiendo ver claramente las divisiones provinciales, rutas y ciudades.
- **Pestana 4: Datos**: Tabla de datos filtrados con opci贸n de **descarga a CSV**.

### Ejecuci贸n
```bash
streamlit run src/app.py
```

## 6. Despliegue con Docker
Se han creado los archivos de configuraci贸n para ejecutar la aplicaci贸n en contenedores.

### Requisitos
- Docker y Docker Compose instalados.

### Ejecuci贸n
1. **Construir y levantar**:
   ```bash
   docker-compose up --build
   ```
2. **Acceder**:
   Navegar a `http://localhost:8501`.

## 7. Automatizaci贸n CI/CD
Se configur贸 un flujo de trabajo en GitHub Actions (`.github/workflows/ci.yml`) que:
1. Ejecuta pruebas unitarias (`pytest`).
2. Verifica que la imagen Docker se construya correctamente.

Esto asegura la calidad del c贸digo y la desplegabilidad en cada push a `main`.


## 8. Modelo Predictivo (Machine Learning)
Se incorpor贸 un modelo de **Regresi贸n Lineal** (`src/model.py`) para proyectar tendencias futuras.

### Caracter铆sticas
- **Entrenamiento On-the-fly**: El modelo se entrena en tiempo real con los datos filtrados por el usuario.
- **Visualizaci贸n**: Muestra la l铆nea hist贸rica y la proyecci贸n futura (punteada) en una nueva pesta帽a **" Predicciones"**.
- **Interactividad**: Slider para elegir cu谩ntos a帽os proyectar hacia el futuro.

## Pr贸ximos Pasos
- Refinar el modelo (considerar estacionalidad si hubiera datos mensuales).
- Agregar m谩s variables predictoras.
